{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BaseLine Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "hockey = pd.read_csv(\"data/clean/train.csv\"\n",
    "                     , sep = ',',encoding = \"ISO-8859-1\",engine='python')\n",
    "hockey['Age'] = 117 - pd.to_numeric(hockey['Born'].str[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit scikit-learn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('preprocessor',\n",
       "                 ColumnTransformer(n_jobs=None, remainder='drop',\n",
       "                                   sparse_threshold=0.3,\n",
       "                                   transformer_weights=None,\n",
       "                                   transformers=[('numerical',\n",
       "                                                  Pipeline(memory=None,\n",
       "                                                           steps=[('imputer',\n",
       "                                                                   SimpleImputer(add_indicator=False,\n",
       "                                                                                 copy=True,\n",
       "                                                                                 fill_value=None,\n",
       "                                                                                 missing_values=nan,\n",
       "                                                                                 strategy='mean',\n",
       "                                                                                 verbose=0)),\n",
       "                                                                  ('scaler',\n",
       "                                                                   StandardScaler(copy=True,\n",
       "                                                                                  with_...\n",
       "                                                                   OneHotEncoder(categorical_features=None,\n",
       "                                                                                 categories=None,\n",
       "                                                                                 drop=None,\n",
       "                                                                                 dtype=<class 'numpy.float64'>,\n",
       "                                                                                 handle_unknown='ignore',\n",
       "                                                                                 n_values=None,\n",
       "                                                                                 sparse=True))],\n",
       "                                                           verbose=False),\n",
       "                                                  ['Pr/St', 'Nat', 'Hand',\n",
       "                                                   'Position', 'Team'])],\n",
       "                                   verbose=False)),\n",
       "                ('regressor',\n",
       "                 Ridge(alpha=100, copy_X=True, fit_intercept=True,\n",
       "                       max_iter=None, normalize=False, random_state=None,\n",
       "                       solver='auto', tol=0.001))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import compose\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn import impute\n",
    "from sklearn import preprocessing\n",
    "\n",
    "y_train = hockey['Salary']\n",
    "X_train = hockey.drop('Salary', axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, random_state=42)\n",
    "\n",
    "def make_pipeline(regressor=None):\n",
    "    \n",
    "    numeric_features = ['Ht', 'Wt', 'DftYr', 'DftRd', 'Ovrl', \n",
    "                        'GP', 'G', 'A', 'A1', 'A2', 'PTS', '+/-', 'E+/-', \n",
    "                        'PIM', 'Shifts', 'TOI', 'TOIX', 'TOI/GP', 'TOI/GP.1', \n",
    "                        'TOI%', 'IPP%', 'SH%', 'SV%', 'PDO', 'F/60', 'A/60', \n",
    "                        'Pct%', 'Diff', 'Diff/60', 'iCF', 'iCF.1', 'iFF', 'iSF', \n",
    "                        'iSF.1', 'iSF.2', 'ixG', 'iSCF', 'iRB', 'iRS', 'iDS', \n",
    "                        'sDist', 'sDist.1', 'Pass', 'iHF', 'iHF.1', 'iHA', 'iHDf', \n",
    "                        'iMiss', 'iGVA', 'iTKA', 'iBLK', 'iGVA.1', 'iTKA.1', \n",
    "                        'iBLK.1', 'BLK%', 'iFOW', 'iFOL', 'iFOW.1', 'iFOL.1', \n",
    "                        'FO%', '%FOT', 'dzFOW', 'dzFOL', 'nzFOW', 'nzFOL', \n",
    "                        'ozFOW', 'ozFOL', 'FOW.Up', 'FOL.Up', 'FOW.Down', \n",
    "                        'FOL.Down', 'FOW.Close', 'FOL.Close', 'OTG', '1G', 'GWG', \n",
    "                        'ENG', 'PSG', 'PSA', 'G.Bkhd', 'G.Dflct', 'G.Slap', 'G.Snap', \n",
    "                        'G.Tip', 'G.Wrap', 'G.Wrst', 'CBar ', 'Post', 'Over', 'Wide', \n",
    "                        'S.Bkhd', 'S.Dflct', 'S.Slap', 'S.Snap', 'S.Tip', 'S.Wrap', 'S.Wrst', \n",
    "                        'iPenT', 'iPenD', 'iPENT', 'iPEND', 'iPenDf', 'NPD', 'Min', \n",
    "                        'Maj', 'Match', 'Misc', 'Game', 'CF', 'CA', 'FF', 'FA', 'SF', \n",
    "                        'SA', 'xGF', 'xGA', 'SCF', 'SCA', 'GF', 'GA', 'RBF', 'RBA', \n",
    "                        'RSF', 'RSA', 'DSF', 'DSA', 'FOW', 'FOL', 'HF', 'HA', 'GVA', \n",
    "                        'TKA', 'PENT', 'PEND', 'OPS', 'DPS', 'PS', 'OTOI', 'Grit', 'DAP', \n",
    "                        'Pace', 'GS', 'GS/G', 'Age']\n",
    "    \n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', impute.SimpleImputer(strategy='mean')),\n",
    "        ('scaler', preprocessing.StandardScaler())])\n",
    "\n",
    "    categorical_features = ['Pr/St', 'Nat', 'Hand', 'Position', 'Team']\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', impute.SimpleImputer(strategy='constant', fill_value='unknown')),\n",
    "        ('onehot', preprocessing.OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "    preprocessor = compose.ColumnTransformer(transformers=[\n",
    "        ('numerical', numeric_transformer, numeric_features),\n",
    "        ('categorical', categorical_transformer, categorical_features)])\n",
    "\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                               ('regressor', regressor)])\n",
    "    \n",
    "    return pipeline\n",
    "\n",
    "regressor = linear_model.Ridge(alpha=100, tol=0.001)\n",
    "pipeline = make_pipeline(regressor)\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_commas(number): \n",
    "    return (\"{:,}\".format(number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$594,350.7 medae on train dataset\n",
      "$717,794.25 medae on test dataset\n"
     ]
    }
   ],
   "source": [
    "y_pred = pipeline.predict(X_train)\n",
    "medae_value_train = add_commas(round(metrics.median_absolute_error(y_train, y_pred), 2))\n",
    "print(f\"${medae_value_train} medae on train dataset\")\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "medae_value_test = add_commas(round(metrics.median_absolute_error(y_test, y_pred), 2))\n",
    "print(f\"${medae_value_test} medae on test dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape_metric(y_test, y_pred):\n",
    "    y_test, y_pred = np.array(y_test), np.array(y_pred)\n",
    "    n = len(y_test)\n",
    "    running_sum = 0\n",
    "    for i in range(n):\n",
    "        running_sum += abs((y_test[i] - y_pred[i])/y_test[i])\n",
    "    return running_sum/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7340679041195847"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mape_metric(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
