{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group Name: The Big One\n",
    "\n",
    "## Group Members: Nicholas Parker, Matthew King, Sean Sturtevant\n",
    "\n",
    "### Dataset: Predict NHL Player Salaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Ask\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can we accurately predict the salary of an NHL player, for the 2016-2017 season?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Acquire\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link to data and data dictionary can be found [here](https://www.kaggle.com/camnugent/predict-nhl-player-salaries#train.csv).\n",
    "\n",
    "The dataset contains 874 records of NHL players and 151 features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Process\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset -fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import matplotlib as plt\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import compose\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn import impute\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import plotly.express as px\n",
    "from rfpimp import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Direct Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hockey_train = pd.read_csv('./data/clean/train.csv', encoding = \"ISO-8859-1\")\n",
    "\n",
    "hockey_test = pd.read_csv('./data/clean/test.csv', encoding = \"ISO-8859-1\")\n",
    "\n",
    "hockey_test_y = pd.read_csv('./data/clean/test_salaries.csv', encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_train_and_test(train_df, test_df, test_response):\n",
    "    \"\"\"\n",
    "    Combine the train and test datasets that were previous split at the source of the data.\n",
    "    \"\"\"\n",
    "    test_df = pd.concat([test_df, test_response], axis = 1)\n",
    "    return pd.concat([train_df, test_df],ignore_index = True, sort = False)\n",
    "\n",
    "hockey = combine_train_and_test(hockey_train, hockey_test, hockey_test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Injecting New Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We want to make sure that players who were all Stars have a feature that indicates such."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below is the link for the all stars from the year 2017.\n",
    "url = \"https://www.hockey-reference.com/allstar/NHL_2017_roster.html\"\n",
    "html = requests.get(url, 'html-parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = pd.read_html(html.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stars = []\n",
    "for table in tables:\n",
    "    all_stars += list(table['Player'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hockey['Name'] = hockey['First Name'] + ' ' + hockey['Last Name']\n",
    "hockey.loc[(hockey.Name.isin(all_stars)), \"All_Star\"] = 1\n",
    "hockey.loc[(hockey.All_Star.isna()), \"All_Star\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nationality_group(df, nationalityCol):\n",
    "    \"\"\"\n",
    "    Reduces the number of values in the Nationality column through binning.\n",
    "    \"\"\"\n",
    "    # A function to feature engineering the 'Nationality column'\n",
    "    # Changes it from 16 unique values to 5 to prevent overfitting\n",
    "    scandanavianNations = ['SWE','NOR','FIN']\n",
    "    otherNations = ['CHE','CZE','FRA','DEU','SVK','AUT','DNK','LVA','HRV','GBR','SVN']\n",
    "    df.loc[(df[nationalityCol].isin(scandanavianNations)), nationalityCol] = 'Scandanavian'\n",
    "    df.loc[(df[nationalityCol].isin(otherNations)), nationalityCol] = 'Other'\n",
    "    return df\n",
    "\n",
    "hockey = nationality_group(hockey, 'Nat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code used to group and remove provinces and states that are only seen a few times\n",
    "# Useful to prevent overfitting to values only observed a few times\n",
    "\n",
    "extreneousStates = ['AK', 'AL', 'AZ', 'CO', 'CT', 'FL', 'IN', 'ME', 'MO', 'NC'\n",
    "                    , 'ND', 'NE', 'NH', 'NJ', 'NL', 'NS', 'OH', 'OK', 'PA'\n",
    "                    , 'PE', 'RI', 'SC', 'TX', 'UT', 'WA']\n",
    "\n",
    "hockey.loc[(hockey['Pr/St'].isin(extreneousStates)),'Pr/St'] = 'Other'\n",
    "\n",
    "# Removing the time variable 'Born' by making a variable 'Age'\n",
    "hockey['Age'] = 117 - pd.to_numeric(hockey['Born'].str[0:2])\n",
    "hockey.loc[(hockey['Age'] > 99), 'Age'] = hockey['Age'] - 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding isNa Cols\n",
    "# These columns are useful to account for missing data\n",
    "def addIsNACol(df, col_name):\n",
    "    \"\"\"\n",
    "    Add columns that indicate whether a record had missing data for specified features.\n",
    "    \"\"\"\n",
    "    na_col_name = col_name + '_is_na'\n",
    "    df[na_col_name] = 0\n",
    "    df.loc[(df[col_name].isna()), na_col_name] = 1\n",
    "    return df\n",
    "\n",
    "hockey = addIsNACol(hockey, 'DftYr')\n",
    "hockey = addIsNACol(hockey, 'iCF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save Processed Data to be used by Model Pipeline\n",
    "Further work with the columns will be done in the pipeline by excluding variable and imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hockey.to_csv('./data/processed/hockey.csv', index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Exploratory Data Analysis\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How large is our dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(874, 159)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hockey.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='font-size:18px'> \n",
    "    Our data contains 874 observations with 154 possible features to be included into a model.<br>\n",
    "    In order to use the features, we should have an understanding of which features contain missing<br>\n",
    "    values, and which features do not contain any missing values.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columns with more than one missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column</th>\n",
       "      <th>Num Missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pr/St</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DftRd</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ovrl</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DftYr</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>sDist.1</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>iCF</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>iHA</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>iRB</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>iSF</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>iFF</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>iHDf</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>iDS</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>GS/G</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PDO</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SH%</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Column  Num Missing\n",
       "0     Pr/St          225\n",
       "2     DftRd          125\n",
       "3      Ovrl          125\n",
       "1     DftYr          125\n",
       "21  sDist.1           25\n",
       "13      iCF           11\n",
       "24      iHA           11\n",
       "18      iRB           11\n",
       "15      iSF           11\n",
       "14      iFF           11\n",
       "25     iHDf           10\n",
       "20      iDS           10\n",
       "62     GS/G            2\n",
       "9       PDO            2\n",
       "7       SH%            2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing = np.sum(hockey.isna())\n",
    "missing_df = pd.DataFrame()\n",
    "missing_df['Column'] = hockey.columns[missing > 0]\n",
    "missing_df['Num Missing'] = missing[missing > 0].values\n",
    "missing_df.sort_values('Num Missing', ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribution of Target Column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='font-size:18px'> \n",
    "    Since we are trying to predict the salary of an NHL player, it might be useful for us to visualize<br>\n",
    "    the distribution of the salary of players.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First verify that we have no missing values in our target column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(hockey.Salary.isna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CAN': 409, 'Other': 79, 'RUS': 36, 'Scandanavian': 111, 'USA': 239}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique, counts = np.unique(hockey.Nat, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is there a salary difference for players who are undrafted vs. those who were drafted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a column for whether or not the player is undrafted.\n",
    "hockey = addIsNACol(hockey, 'DftYr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "drafted = hockey.loc[(hockey.DftYr_is_na == 0)][['Salary', 'DftYr_is_na']]\n",
    "undrafted = hockey.loc[(hockey.DftYr_is_na == 1)][['Salary', 'DftYr_is_na']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** The code below will be commented out, because we aren't sure if rpy2 is installed on your machine.\n",
    "#### We will still link to the visualization that was created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %R -i undrafted\n",
    "# %R -i drafted\n",
    "# %R library(ggplot2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%R -w 8 -h 4 --units in -r 200\n",
    "# ggplot() +\n",
    "#     geom_density(aes(x=Salary), color=\"Blue\", data=undrafted) + \n",
    "#     geom_density(aes(x=Salary), color=\"Red\", data=drafted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/SalaryDist.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='font-size:18px'> \n",
    "    From what we can see above, there doesn't appear to be much of a difference between players<br>\n",
    "    salary depending on whether or not they were drafted or if they were undrafted.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Is there a correlation between Age and Salary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "age = hockey[['Salary', 'Age']]\n",
    "# %R -i age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%R -w 8 -h 4 --units in -r 200\n",
    "# ggplot(aes(x=Age, y=Salary), data=age) +\n",
    "#     geom_point(aes(x=Age, y=Salary), color='blue', alpha=0.7, data=age) +\n",
    "#     geom_smooth(method = \"lm\", color=\"red\", alpha=0.3)\n",
    "# # ggsave(\"age.png\", dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/age.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How many different players Nationality is there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "hockey_clean = combine_train_and_test(hockey_train, hockey_test, hockey_test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "hockey_clean_nat = hockey_clean.groupby('Nat').agg({'Salary':'count'}).reset_index()\n",
    "hockey_clean_nat['Dataset'] = \"Raw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "hockey_nat = hockey.groupby('Nat').agg({'Salary':'count'}).reset_index()\n",
    "hockey_nat.loc[(hockey_nat.Nat == \"Other\"), \"Nat\"] = \"Other Countries\"\n",
    "hockey_nat['Dataset'] = \"Processed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %R -i hockey_nat\n",
    "# %R -i hockey_clean_nat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%R -w 8 -h 6 --units in -r 200\n",
    "# ggplot() +\n",
    "#     geom_bar(aes(x=reorder(Nat, Salary), y=Salary), stat=\"identity\", data=hockey_clean_nat) +\n",
    "#     ylab(\"Number of Players\\n\") +\n",
    "#     xlab(\"Country\\n\") +\n",
    "#     coord_flip() +\n",
    "#     theme(axis.ticks.y=element_blank(), axis.text.y=element_text(size=12, color=\"black\"), axis.title.y=element_text(size=14),\n",
    "#           axis.title.x=element_text(size=14), axis.ticks.x=element_blank(), axis.text.x=element_text(size=12,color=\"black\"))\n",
    "# # ggsave(\"images/country1.png\", dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/country1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='font-size:18px'> \n",
    "    After looking at the number of players by each country, we noticed that many of the players <br>\n",
    "    primarily from four different countries. There were also many different European countries that<br>\n",
    "    that we thought would be appropriate to group together since how few the number of counts that<br>\n",
    "    there was. Below, you can see the number of groups that we ended up grouping Nationality into.<br><br>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After processing the data, how many Nationality categories to we have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CAN': 409, 'Other': 79, 'RUS': 36, 'Scandanavian': 111, 'USA': 239}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique, counts = np.unique(hockey.Nat, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%R -w 8 -h 6 --units in -r 200\n",
    "# ggplot() +\n",
    "#     geom_bar(aes(x=reorder(Nat, Salary), y=Salary), stat=\"identity\", data=hockey_nat) +\n",
    "#     ylab(\"Number of Players\\n\") +\n",
    "#     xlab(\"Country\\n\") +\n",
    "#     coord_flip() +\n",
    "#     theme(axis.ticks.y=element_blank(), axis.text.y=element_text(size=12, color=\"black\"), axis.title.y=element_text(size=14),\n",
    "#           axis.title.x=element_text(size=14), axis.ticks.x=element_blank(), axis.text.x=element_text(size=12,color=\"black\"))\n",
    "# # ggsave(\"images/country2.png\", dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/country2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Models\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_commas(number):\n",
    "    \"\"\"\n",
    "    Adds commas to values greater that 1,000 for evaluation metrics.\n",
    "    \"\"\"\n",
    "    return (\"{:,}\".format(number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape_metric(y_test, y_pred):\n",
    "    \"\"\"\n",
    "    Calculates the mean absolute percentage error.\n",
    "    \"\"\"\n",
    "    y_test, y_pred = np.array(y_test), np.array(y_pred)\n",
    "    return np.mean((np.abs(y_test - y_pred) / (0.5*(np.abs(y_test)+np.abs(y_pred)))))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train, test, and validation sets of the data.\n",
    "y = hockey['Salary']\n",
    "X = hockey.drop('Salary', axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=99) # Split to obtain the test set\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, random_state=99) # Split to obtain the validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create separate lists of numeric and categorical features to be passed through the pipeline.\n",
    "numeric_baseline = [feature for feature in X_train.columns if np.issubdtype(X_train[feature], np.number)]\n",
    "categorical_baseline = [feature for feature in X_train.columns if feature not in numeric_baseline]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('preprocessor',\n",
       "                 ColumnTransformer(n_jobs=None, remainder='drop',\n",
       "                                   sparse_threshold=0.3,\n",
       "                                   transformer_weights=None,\n",
       "                                   transformers=[('numerical',\n",
       "                                                  Pipeline(memory=None,\n",
       "                                                           steps=[('imputer',\n",
       "                                                                   SimpleImputer(add_indicator=False,\n",
       "                                                                                 copy=True,\n",
       "                                                                                 fill_value=None,\n",
       "                                                                                 missing_values=nan,\n",
       "                                                                                 strategy='median',\n",
       "                                                                                 verbose=0)),\n",
       "                                                                  ('scaler',\n",
       "                                                                   StandardScaler(copy=True,\n",
       "                                                                                  wit...\n",
       "                                                                                 dtype=<class 'numpy.float64'>,\n",
       "                                                                                 handle_unknown='ignore',\n",
       "                                                                                 n_values=None,\n",
       "                                                                                 sparse=True))],\n",
       "                                                           verbose=False),\n",
       "                                                  ['Born', 'City', 'Pr/St',\n",
       "                                                   'Cntry', 'Nat', 'Hand',\n",
       "                                                   'Last Name', 'First Name',\n",
       "                                                   'Position', 'Team',\n",
       "                                                   'Name'])],\n",
       "                                   verbose=False)),\n",
       "                ('regressor',\n",
       "                 Ridge(alpha=100, copy_X=True, fit_intercept=True,\n",
       "                       max_iter=None, normalize=False, random_state=None,\n",
       "                       solver='auto', tol=0.001))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_pipeline_ridge(regressor=None):\n",
    "    \"\"\"\n",
    "    Creates pipeline to perform transformations on numeric and categorical features \n",
    "    and pass into a Ridge Regression Model.\n",
    "    \"\"\"\n",
    "    numeric_features = numeric_baseline\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', impute.SimpleImputer(strategy='median')),\n",
    "        ('scaler', preprocessing.StandardScaler())])\n",
    "\n",
    "    categorical_features = categorical_baseline\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', impute.SimpleImputer(strategy='constant', fill_value='unknown')),\n",
    "        ('onehot', preprocessing.OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "    preprocessor = compose.ColumnTransformer(transformers=[\n",
    "        ('numerical', numeric_transformer, numeric_features),\n",
    "        ('categorical', categorical_transformer, categorical_features)])\n",
    "\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                               ('regressor', regressor)])\n",
    "    \n",
    "    return pipeline\n",
    "\n",
    "regressor = linear_model.Ridge(alpha=100, tol=0.001)\n",
    "pipeline = make_pipeline_ridge(regressor)\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Baseline Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1453721.08403749 1303208.72307592 1302488.44918904 1700854.91509345\n",
      " 1795888.74975077 1762539.65712339 1334242.46954355 1455163.9307866\n",
      " 1497014.57788712 1171192.24732952]\n",
      "\n",
      "1,477,631.48 average cross validation rmse\n"
     ]
    }
   ],
   "source": [
    "mean_squared_error_scorer = make_scorer(metrics.mean_squared_error)\n",
    "cross_val_bl = np.sqrt(cross_val_score(pipeline, \n",
    "                                       X_train, \n",
    "                                       y_train, \n",
    "                                       scoring=mean_squared_error_scorer,\n",
    "                                       cv=10))\n",
    "print(cross_val_bl)\n",
    "print('')\n",
    "print(f\"{add_commas(round(cross_val_bl.mean(), 2))} average cross validation rmse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Root Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,182,093.04 rmse on train dataset\n",
      "1,534,370.47 rmse on validation dataset\n"
     ]
    }
   ],
   "source": [
    "y_pred = pipeline.predict(X_train)\n",
    "rmse_value_train = add_commas(round(np.sqrt(metrics.mean_squared_error(y_train, y_pred)), 2))\n",
    "print(f\"{rmse_value_train} rmse on train dataset\")\n",
    "\n",
    "y_pred = pipeline.predict(X_validation)\n",
    "rmse_value_validation = add_commas(round(np.sqrt(metrics.mean_squared_error(y_validation, y_pred)), 2))\n",
    "RidgeRMSE = round(np.sqrt(metrics.mean_squared_error(y_validation, y_pred)), 2)\n",
    "print(f\"{rmse_value_validation} rmse on validation dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Median Absolute Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$620,274.51 medae on train dataset\n",
      "$731,403.67 medae on validation dataset\n"
     ]
    }
   ],
   "source": [
    "y_pred = pipeline.predict(X_train)\n",
    "medae_value_train = add_commas(round(metrics.median_absolute_error(y_train, y_pred), 2))\n",
    "print(f\"${medae_value_train} medae on train dataset\")\n",
    "\n",
    "y_pred = pipeline.predict(X_validation)\n",
    "medae_value_validation = add_commas(round(metrics.median_absolute_error(y_validation, y_pred), 2))\n",
    "RidgeMedAE = medae_value_validation\n",
    "print(f\"${medae_value_validation} medae on validation dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean Absolute Percentage Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48.43% sMAPE on train dataset\n",
      "57.93% sMAPE on validation dataset\n"
     ]
    }
   ],
   "source": [
    "y_pred = pipeline.predict(X_train)\n",
    "mape_value_train = round(mape_metric(y_train, y_pred), 2)\n",
    "print(f\"{mape_value_train}% sMAPE on train dataset\")\n",
    "\n",
    "y_pred = pipeline.predict(X_validation)\n",
    "mape_value_validation = round(mape_metric(y_validation, y_pred), 2)\n",
    "RidgesMAPE = mape_value_validation\n",
    "print(f\"{mape_value_validation}% sMAPE on validation dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Selection Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### knn Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonpredictive_features = ['ENG', 'Wide', 'Over', 'PSG', 'PSA', 'S.Dflct', 'G.Bkhd', 'Post', 'G.Dflct', 'CBar ', 'G.Slap', 'G.Snap', 'G.Wrst', 'G.Wrap', 'G.Tip', 'S.Bkhd', 'Min', 'S.Slap', 'Misc', 'Noise', 'DAP', 'Grit', 'PS', 'DPS', 'OPS', 'DSA', 'DSF', 'Game', 'Match', 'S.Snap', 'Maj', '1G', 'NPD', 'iPenDf', 'iPenD', 'iPenT', 'S.Wrst', 'S.Wrap', 'S.Tip', 'GWG', 'FOL.Down', 'OTG', 'PIM', 'iSF.1', 'iCF.1', 'Diff', 'Pct%', 'FOL.Close', 'TOI/GP.1', 'TOI/GP', 'TOI', 'Shifts', 'E+/-', 'sDist', '+/-', 'PTS', 'A2', 'A1', 'A', 'G', 'GP', 'Wt', 'Ht', 'iSF.2', 'Age', 'iFOW', 'iBLK', 'iFOL', 'dzFOL', 'nzFOW', 'nzFOL', 'ozFOW', 'ozFOL', 'dzFOW', 'FOL.Up', 'FOW.Up', 'iTKA', 'iGVA', 'iMiss', 'FOW.Down', 'iHF', 'FOW.Close', 'FO%', 'Position', 'Team', 'PEND', 'TOIX', 'GA', 'xGA', 'iSCF', 'iPEND', 'sDist.1', 'iHF.1', 'PDO', 'Hand', 'SCA', 'iTKA.1', 'SA', 'IPP%', 'ixG', 'FA', 'Pace', 'iGVA.1', 'SV%', 'RBF', 'PENT', 'F/60', 'GVA', 'TKA', 'FOW', 'Diff/60']\n",
    "\n",
    "# For KNN, we only want to include the numeric variables.\n",
    "# At the moment we do not want to consider some of the categorical \n",
    "# variables since KNN will not handle these naturally.\n",
    "numeric_knn = [feature for feature in X_train.columns if np.issubdtype(X_train[feature], np.number) \n",
    "                      and feature not in nonpredictive_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to be able to fit the knn model, we will need to make sure that our pipeline is suited to handle the data for KNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pipeline_knn(knn=None):\n",
    "    \"\"\"\n",
    "    Creates pipeline that performs separate transformations on the categorical and numerical features\n",
    "    for a KNN algorithm.\n",
    "    \"\"\"\n",
    "    \n",
    "    # All predictive numeric features\n",
    "    numeric_features = numeric_knn\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        # Impute any missing values with the median.\n",
    "        ('imputer', impute.SimpleImputer(strategy='median')),\n",
    "        # Make sure that all values are Normalized for KNN. \n",
    "        # Since we are going to look at points that are similar in\n",
    "        # terms of euclidean space, we need all features on the same\n",
    "        # scale.\n",
    "        ('normalizer', preprocessing.Normalizer())])\n",
    "\n",
    "    preprocessor = compose.ColumnTransformer(transformers=[\n",
    "        ('numerical', numeric_transformer, numeric_features)])\n",
    "\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                               ('knn', knn)])\n",
    "    \n",
    "    return pipeline\n",
    "\n",
    "knn = KNeighborsRegressor()\n",
    "pipeline_knn = make_pipeline_knn(knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done  75 out of  75 | elapsed:    2.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=Pipeline(memory=None,\n",
       "                                      steps=[('preprocessor',\n",
       "                                              ColumnTransformer(n_jobs=None,\n",
       "                                                                remainder='drop',\n",
       "                                                                sparse_threshold=0.3,\n",
       "                                                                transformer_weights=None,\n",
       "                                                                transformers=[('numerical',\n",
       "                                                                               Pipeline(memory=None,\n",
       "                                                                                        steps=[('imputer',\n",
       "                                                                                                SimpleImputer(add_indicator=False,\n",
       "                                                                                                              copy=True,\n",
       "                                                                                                              fill_value=None,\n",
       "                                                                                                              missing_values=nan,\n",
       "                                                                                                              st...\n",
       "                                                                  metric_params=None,\n",
       "                                                                  n_jobs=None,\n",
       "                                                                  n_neighbors=5,\n",
       "                                                                  p=2,\n",
       "                                                                  weights='uniform'))],\n",
       "                                      verbose=False),\n",
       "                   iid='warn', n_iter=15, n_jobs=-1,\n",
       "                   param_distributions={'knn__algorithm': ['ball_tree',\n",
       "                                                           'kd_tree', 'auto'],\n",
       "                                        'knn__n_neighbors': [8, 9, 10, 15],\n",
       "                                        'knn__weights': ['distance',\n",
       "                                                         'uniform']},\n",
       "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=1)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_random_cv_knn():\n",
    "    \"\"\"\n",
    "    Define hyperparameter search space for KNN algorithm\n",
    "    Instantiate RandomizedSearchCV with the pipeline.\n",
    "    \"\"\"\n",
    "    \n",
    "    algo = ['ball_tree', 'kd_tree', 'auto']\n",
    "    weights = ['distance', 'uniform']\n",
    "    neighbors = [8, 9, 10, 15]\n",
    "    hyperparameters = dict(knn__algorithm=algo,\n",
    "                          knn__n_neighbors=neighbors,\n",
    "                          knn__weights=weights)\n",
    "    \n",
    "    reg_random_cv = RandomizedSearchCV(pipeline_knn, \n",
    "                                       hyperparameters, \n",
    "                                       cv=5, \n",
    "                                       n_iter=15, \n",
    "                                       verbose=1,\n",
    "                                       random_state=42,\n",
    "                                       n_jobs=-1)\n",
    "    \n",
    "    return reg_random_cv\n",
    "\n",
    "model_knn = make_random_cv_knn()\n",
    "model_knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1632972.63524097 1673164.81004026 1595420.0474987  1861409.78294072\n",
      " 1967382.04380449 2067575.95721091 1642673.46192757 1675774.57859102\n",
      " 1589030.16179889 1150602.21324031]\n",
      "\n",
      "1,685,600.57 average cross validation rmse\n"
     ]
    }
   ],
   "source": [
    "mean_squared_error_scorer = make_scorer(metrics.mean_squared_error)\n",
    "cross_val_knn = np.sqrt(cross_val_score(model_knn.best_estimator_, \n",
    "                                       X_train, \n",
    "                                       y_train, \n",
    "                                       scoring=mean_squared_error_scorer,\n",
    "                                       cv=10))\n",
    "print(cross_val_knn)\n",
    "print('')\n",
    "print(f\"{add_commas(round(cross_val_knn.mean(), 2))} average cross validation rmse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Root Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,539,761.45 rmse on train dataset\n",
      "1,649,920.01 rmse on validation dataset\n"
     ]
    }
   ],
   "source": [
    "knn_y_pred = model_knn.best_estimator_.predict(X_train)\n",
    "rmse_value_train = add_commas(round(np.sqrt(metrics.mean_squared_error(y_train, knn_y_pred)), 2))\n",
    "print(f\"{rmse_value_train} rmse on train dataset\")\n",
    "\n",
    "knn_y_pred = model_knn.best_estimator_.predict(X_validation)\n",
    "rmse_value_validation = add_commas(round(np.sqrt(metrics.mean_squared_error(y_validation, knn_y_pred)), 2))\n",
    "KNNRMSE = round(np.sqrt(metrics.mean_squared_error(y_validation, knn_y_pred)), 2)\n",
    "print(f\"{rmse_value_validation} rmse on validation dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Median Absolute Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$490,833.33 medae on train dataset\n",
      "$540,881.94 medae on validation dataset\n"
     ]
    }
   ],
   "source": [
    "knn_y_pred = model_knn.best_estimator_.predict(X_train)\n",
    "medae_value_train = add_commas(round(metrics.median_absolute_error(y_train, knn_y_pred), 2))\n",
    "print(f\"${medae_value_train} medae on train dataset\")\n",
    "\n",
    "knn_y_pred = model_knn.best_estimator_.predict(X_validation)\n",
    "medae_value_validation = add_commas(round(metrics.median_absolute_error(y_validation, knn_y_pred), 2))\n",
    "KNNRMedAE = medae_value_validation\n",
    "print(f\"${medae_value_validation:} medae on validation dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean Absolute Percentage Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.87% sMAPE on train dataset\n",
      "43.57% sMAPE on validation dataset\n"
     ]
    }
   ],
   "source": [
    "knn_y_pred = model_knn.best_estimator_.predict(X_train)\n",
    "mape_value_train = round(mape_metric(y_train, knn_y_pred), 2)\n",
    "print(f\"{mape_value_train}% sMAPE on train dataset\")\n",
    "\n",
    "knn_y_pred = model_knn.best_estimator_.predict(X_validation)\n",
    "mape_value_validation = round(mape_metric(y_validation, knn_y_pred), 2)\n",
    "KNNsMAPE = mape_value_validation\n",
    "print(f\"{mape_value_validation}% sMAPE on validation dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are features which should have no affect on Salary, like First Name\n",
    "illogical_features = ['Born', 'City', 'Last Name', 'First Name', 'Name', 'Cntry']\n",
    "# These are features which are repeated later on with updated stats\n",
    "redundant_features = ['TOI/GP', 'iCF', 'iSF', 'iSF.1', 'sDist', 'iHF', 'iGVA', 'iTKA', 'iBLK', 'iFOW', 'iFOL']\n",
    "# These are features found to be non-predictive using Parrt's rfpimp package\n",
    "\n",
    "drop_list = illogical_features + redundant_features\n",
    "\n",
    "numeric_rf = [feature for feature in X_train.columns if np.issubdtype(X_train[feature], np.number) \n",
    "                      and feature not in drop_list]\n",
    "categorical_rf = [feature for feature in X_train.columns if feature not in numeric_rf\n",
    "                       and feature not in drop_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pipeline_rf(regressor=None):\n",
    "    \"\"\"\n",
    "    Creates pipeline that performs separate transformations on the categorical and numerical features.\n",
    "    \"\"\"\n",
    "    \n",
    "    numeric_features = numeric_rf\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', impute.SimpleImputer(strategy='median'))])\n",
    "\n",
    "    categorical_features = categorical_rf\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', impute.SimpleImputer(strategy='constant', fill_value='unknown')),\n",
    "        ('onehot', preprocessing.OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "    preprocessor = compose.ColumnTransformer(transformers=[\n",
    "        ('numerical', numeric_transformer, numeric_features),\n",
    "        ('categorical', categorical_transformer, categorical_features)])\n",
    "\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                               ('regressor', regressor)])\n",
    "    \n",
    "    return pipeline\n",
    "\n",
    "regressor_rf = RandomForestRegressor()\n",
    "pipeline_rf = make_pipeline_rf(regressor_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "def make_random_cv():\n",
    "    \"\"\"\n",
    "    Define hyperparameter search space\n",
    "    Instantiate RandomizedSearchCV with the pipeline.\n",
    "    \"\"\"\n",
    "    \n",
    "    bootstrap = ['True', 'False']\n",
    "    oob_score = ['True', 'False']\n",
    "    max_features = ['auto', 'sqrt']\n",
    "    min_samples_leaf = [2, 3, 5, 6 , 7, 8, 9, 10]\n",
    "    n_estimators = [100, 150, 200, 300, 500]\n",
    "    hyperparameters = dict(regressor__min_samples_leaf=min_samples_leaf,\n",
    "                          regressor__bootstrap=bootstrap,\n",
    "                          regressor__max_features=max_features,\n",
    "                          regressor__n_estimators=n_estimators,\n",
    "                          regressor__oob_score=oob_score)\n",
    "    reg_random_cv = RandomizedSearchCV(pipeline_rf, \n",
    "                                       hyperparameters, \n",
    "                                       cv=5, \n",
    "                                       n_iter=15, \n",
    "                                       verbose=1,\n",
    "                                       random_state=42,\n",
    "                                       n_jobs=-1)\n",
    "    \n",
    "    return reg_random_cv\n",
    "\n",
    "model_rf = make_random_cv()\n",
    "model_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross Validation Scores for Best Estimator from Randomized Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error_scorer = make_scorer(metrics.mean_squared_error)\n",
    "cross_val_rf = np.sqrt(cross_val_score(model_rf.best_estimator_, \n",
    "                                       X_train, \n",
    "                                       y_train, \n",
    "                                       scoring=mean_squared_error_scorer,\n",
    "                                       cv=10))\n",
    "print(cross_val_rf)\n",
    "print('')\n",
    "print(f\"{add_commas(round(cross_val_rf.mean(), 2))} average cross validation rmse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Root Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_rf.predict(X_train)\n",
    "rmse_value_train = add_commas(round(np.sqrt(metrics.mean_squared_error(y_train, y_pred)), 2))\n",
    "print(f\"{rmse_value_train} rmse on train dataset\")\n",
    "\n",
    "y_pred = model_rf.predict(X_validation)\n",
    "rmse_value_validation = add_commas(round(np.sqrt(metrics.mean_squared_error(y_validation, y_pred)), 2))\n",
    "RFRMSE = round(np.sqrt(metrics.mean_squared_error(y_validation, y_pred)), 2)\n",
    "print(f\"{rmse_value_validation} rmse on validation dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Median Absolute Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_rf.predict(X_train)\n",
    "medae_value_train = add_commas(round(metrics.median_absolute_error(y_train, y_pred), 2))\n",
    "print(f\"${medae_value_train} medae on train dataset\")\n",
    "\n",
    "y_pred = model_rf.predict(X_validation)\n",
    "medae_value_validation = add_commas(round(metrics.median_absolute_error(y_validation, y_pred), 2))\n",
    "RFMedAE = medae_value_validation\n",
    "print(f\"${medae_value_validation} medae on validation dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean Absolute Percentage Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_rf.predict(X_train)\n",
    "mape_value_train = round(mape_metric(y_train, y_pred), 2)\n",
    "print(f\"{mape_value_train}% sMAPE on train dataset\")\n",
    "\n",
    "y_pred = model_rf.predict(X_validation)\n",
    "mape_value_validation = round(mape_metric(y_validation, y_pred), 2)\n",
    "RFsMAPE = mape_value_validation\n",
    "print(f\"{mape_value_validation}% sMAPE on validation dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model Choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Performance Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotWithPlotly(performance_df):\n",
    "    fig = px.bar(performance_df, x = 'Models', y = 'RMSE'\n",
    "            , color = 'RMSE'\n",
    "            , hover_data= [\"MedAE\",'sMAPE']\n",
    "            )\n",
    "    fig.show()\n",
    "    \n",
    "def plotWithMatplotlib(performance_df):\n",
    "    performance_df[['Models','RMSE']].plot(kind = 'bar', x = 'Models', y = 'RMSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_performance_df = pd.DataFrame()\n",
    "model_performance_df['Models'] = ['Ridge','Random Forest','KNN']\n",
    "model_performance_df['RMSE'] = [RidgeRMSE, RFRMSE, KNNRMSE]\n",
    "model_performance_df['MedAE'] = [RidgeMedAE, RFMedAE, KNNRMedAE]\n",
    "model_performance_df['sMAPE'] = [RidgesMAPE, RFsMAPE, KNNsMAPE]\n",
    "model_performance_df['RMSE'] = pd.to_numeric(model_performance_df['RMSE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    plotWithPlotly(model_performance_df)\n",
    "except:\n",
    "    plotWithMatplotlib(model_performance_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using RMSE as our North Star evaluation metric to choose a model, we ended up choosing to continue with the Random Forest Model because it consistently had the best validation set test scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the rfpimp package by ParrT, we look at our best model and estimate feature importance\n",
    "I = importances(model_rf.best_estimator_, X_train, y_train)\n",
    "I.reset_index(inplace = True)\n",
    "\n",
    "# These features deemed 'not important are dropped'\n",
    "# It doesn't affect the training score much, but a simpler model generalizes better\n",
    "print(len(list(I.loc[(I.Importance <= 0)]['Feature'])), 'Features')\n",
    "new_drop_list = list(I.loc[(I.Importance <= 0)]['Feature'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain the model on the new drop list\n",
    "numeric_rf = [feature for feature in X_train.columns if np.issubdtype(X_train[feature], np.number) \n",
    "                      and feature not in new_drop_list]\n",
    "categorical_rf = [feature for feature in X_train.columns if feature not in numeric_rf\n",
    "                       and feature not in new_drop_list]\n",
    "\n",
    "regressor_rf = RandomForestRegressor()\n",
    "pipeline_rf = make_pipeline_rf(regressor_rf)\n",
    "model_rf = make_random_cv()\n",
    "model_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Deliver\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Median Absolute Error Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_rf.predict(X_test)\n",
    "medae_value_test = add_commas(round(metrics.median_absolute_error(y_test, y_pred), 2))\n",
    "print(f\"${medae_value_test:} medae on test dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Root Mean Squared Error Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_rf.predict(X_test)\n",
    "rmse_value_test = add_commas(round(np.sqrt(metrics.mean_squared_error(y_test, y_pred)), 2))\n",
    "print(f\"{rmse_value_test} rmse on test dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mean Absolute Percentage Error Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_rf.predict(X_test)\n",
    "mape_value_test = round(mape_metric(y_test, y_pred), 2)\n",
    "print(f\"{mape_value_test}% sMAPE on test dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary and Takeaways"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='font-size:18px'> \n",
    "To predict NHL player salaries, we fitted three regressor models, a Ridge Regression model, a KNN model, and a Random Forest model. After running our models against each other, we looked at three different evaluation metrics for each. Each evaluation metric served a unique purpose for being included throughout our process. Median Absolute Error (MedAE) is the most useful for external communication of our model as it is the most interpretable. Being able to discuss an evaluation metric in terms of dollars allows for those without machine learning experience to understand exactly what that metric is telling us about the error in our model. Symmetric Mean Absolute Percent Error (sMAPE) is useful to us because it provides a completely different interpretation. Since the values we are predicting are so large it is likely that the errors may also be large numbers, so being able to interpret the error in relation to the actual values is useful. For example, a median absolute error of hundreds of thousands of dollars seems like it is abnormally large, but in comparison to the actual y-values this may be a fairly decent prediction error. Finally, our 'North Star' metric that we use to pick a model is the Root Mean Square Error (RMSE). RMSE minimizes the loss, and unlike MAPE, RMSE is symmetric. MAPE sufferes from asymmetry.</span>\n",
    "\n",
    "<span style='font-size:18px'> \n",
    "Our single best model was our Random Forest model which had the lowest of all three evaluation metrics on the validation sets, included an RMSE of 1.4 million. We then ran this model on the test set. To interpret the test set results, we can use the sMAPE of 38\\% and \\\\$540,125 on the test set. A 38\\% sMAPE score tells us that the average error was 38\\% of the actual salary and a MedAE score of value of \\\\$540,125 tells us that the median error from our model is \\\\$540,125 off from the actual salary. Even with such large salary values this error is quite large and we do not necessarily believe this model should be pushed into production to any NHL General Managers to give them a way to predict salary in the ever-changing salary cap environment of the NHL.</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
