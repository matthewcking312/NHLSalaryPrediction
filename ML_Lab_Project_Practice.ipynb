{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BaseLine Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "hockey = pd.read_csv(\"/Users/seanmac/Documents/Mod_2/ML_Lab/predict-nhl-player-salaries/train.csv\"\n",
    "                     , sep = ',',encoding = \"ISO-8859-1\",engine='python')\n",
    "hockey['Age'] = 117 - pd.to_numeric(hockey['Born'].str[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit scikit-learn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import compose\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn import impute\n",
    "from sklearn import preprocessing\n",
    "\n",
    "y_train = hockey['Salary']\n",
    "X_train = hockey.drop('Salary', axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train)\n",
    "\n",
    "def make_pipeline(regressor=None):\n",
    "    \n",
    "    numeric_features = ['Ht', 'Wt', 'DftYr', 'DftRd', 'Ovrl', \n",
    "                        'GP', 'G', 'A', 'A1', 'A2', 'PTS', '+/-', 'E+/-', \n",
    "                        'PIM', 'Shifts', 'TOI', 'TOIX', 'TOI/GP', 'TOI/GP.1', \n",
    "                        'TOI%', 'IPP%', 'SH%', 'SV%', 'PDO', 'F/60', 'A/60', \n",
    "                        'Pct%', 'Diff', 'Diff/60', 'iCF', 'iCF.1', 'iFF', 'iSF', \n",
    "                        'iSF.1', 'iSF.2', 'ixG', 'iSCF', 'iRB', 'iRS', 'iDS', \n",
    "                        'sDist', 'sDist.1', 'Pass', 'iHF', 'iHF.1', 'iHA', 'iHDf', \n",
    "                        'iMiss', 'iGVA', 'iTKA', 'iBLK', 'iGVA.1', 'iTKA.1', \n",
    "                        'iBLK.1', 'BLK%', 'iFOW', 'iFOL', 'iFOW.1', 'iFOL.1', \n",
    "                        'FO%', '%FOT', 'dzFOW', 'dzFOL', 'nzFOW', 'nzFOL', \n",
    "                        'ozFOW', 'ozFOL', 'FOW.Up', 'FOL.Up', 'FOW.Down', \n",
    "                        'FOL.Down', 'FOW.Close', 'FOL.Close', 'OTG', '1G', 'GWG', \n",
    "                        'ENG', 'PSG', 'PSA', 'G.Bkhd', 'G.Dflct', 'G.Slap', 'G.Snap', \n",
    "                        'G.Tip', 'G.Wrap', 'G.Wrst', 'CBar ', 'Post', 'Over', 'Wide', \n",
    "                        'S.Bkhd', 'S.Dflct', 'S.Slap', 'S.Snap', 'S.Tip', 'S.Wrap', 'S.Wrst', \n",
    "                        'iPenT', 'iPenD', 'iPENT', 'iPEND', 'iPenDf', 'NPD', 'Min', \n",
    "                        'Maj', 'Match', 'Misc', 'Game', 'CF', 'CA', 'FF', 'FA', 'SF', \n",
    "                        'SA', 'xGF', 'xGA', 'SCF', 'SCA', 'GF', 'GA', 'RBF', 'RBA', \n",
    "                        'RSF', 'RSA', 'DSF', 'DSA', 'FOW', 'FOL', 'HF', 'HA', 'GVA', \n",
    "                        'TKA', 'PENT', 'PEND', 'OPS', 'DPS', 'PS', 'OTOI', 'Grit', 'DAP', \n",
    "                        'Pace', 'GS', 'GS/G', 'Age']\n",
    "    \n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', impute.SimpleImputer(strategy='mean')),\n",
    "        ('scaler', preprocessing.StandardScaler())])\n",
    "\n",
    "    categorical_features = ['Pr/St', 'Nat', 'Hand', 'Position', 'Team']\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', impute.SimpleImputer(strategy='constant', fill_value='unknown')),\n",
    "        ('onehot', preprocessing.OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "    preprocessor = compose.ColumnTransformer(transformers=[\n",
    "        ('numerical', numeric_transformer, numeric_features),\n",
    "        ('categorical', categorical_transformer, categorical_features)])\n",
    "\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                               ('regressor', regressor)])\n",
    "    \n",
    "    return pipeline\n",
    "\n",
    "regressor = linear_model.Ridge(alpha=100, tol=0.001)\n",
    "pipeline = make_pipeline(regressor)\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipeline.predict(X_train)\n",
    "medae_value_train = metrics.median_absolute_error(y_train, y_pred)\n",
    "print(f\"${medae_value_train:.4f} medae on train dataset\")\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "medae_value_test = metrics.median_absolute_error(y_test, y_pred)\n",
    "print(f\"${medae_value_test:.4f} medae on test dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Model Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"/Users/seanmac/Documents/Mod_2/ML_Lab/predict-nhl-player-salaries/train.csv\"\n",
    "                     , sep = ',',encoding = \"ISO-8859-1\",engine='python')\n",
    "\n",
    "test = pd.read_csv(\"/Users/seanmac/Documents/Mod_2/ML_Lab/predict-nhl-player-salaries/test.csv\"\n",
    "                     , sep = ',',encoding = \"ISO-8859-1\",engine='python')\n",
    "\n",
    "test_y = pd.read_csv('/Users/seanmac/Documents/Mod_2/ML_Lab/predict-nhl-player-salaries/test_salaries.csv',\n",
    "                     sep = ',',encoding = \"ISO-8859-1\",engine='python')\n",
    "                     \n",
    "def combine_train_and_test(train_df, test_df, test_response):\n",
    "    test_df = pd.concat([test_df, test_response], axis = 1)\n",
    "    return pd.concat([train_df, test_df],ignore_index = True, sort = False)\n",
    "\n",
    "hockey = combine_train_and_test(train, test, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hockey['Age'] = 117 - pd.to_numeric(hockey['Born'].str[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nationality_group(df, nationalityCol):\n",
    "    # A function to feature engineering the 'Nationality column'\n",
    "    # Changes it from 16 unique values to 5 to prevent overfitting\n",
    "    scandanavianNations = ['SWE','NOR','FIN']\n",
    "    otherNations = ['CHE','CZE','FRA','DEU','SVK','AUT','DNK','LVA','HRV','GBR']\n",
    "    df.loc[(df[nationalityCol].isin(scandanavianNations)), nationalityCol] = 'Scandanavian'\n",
    "    df.loc[(df[nationalityCol].isin(otherNations)), nationalityCol] = 'Other'\n",
    "    return df\n",
    "hockey = nationality_group(hockey, 'Nat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code used to group and remove provinces and states that are only seen a few times\n",
    "# Useful to prevent overfitting\n",
    "prs = hockey.groupby('Pr/St').agg({'Pr/St':['count']}).reset_index()\n",
    "prs.columns = ['pr/st','count']\n",
    "extreneousStates = list(prs.loc[(prs['count'] < 10)]['pr/st'])\n",
    "hockey.loc[(hockey['Pr/St'].isin(extreneousStates)),'Pr/St'] = 'Other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Salary</th>\n",
       "      <th>Born</th>\n",
       "      <th>City</th>\n",
       "      <th>Pr/St</th>\n",
       "      <th>Cntry</th>\n",
       "      <th>Nat</th>\n",
       "      <th>Ht</th>\n",
       "      <th>Wt</th>\n",
       "      <th>DftYr</th>\n",
       "      <th>DftRd</th>\n",
       "      <th>...</th>\n",
       "      <th>OPS</th>\n",
       "      <th>DPS</th>\n",
       "      <th>PS</th>\n",
       "      <th>OTOI</th>\n",
       "      <th>Grit</th>\n",
       "      <th>DAP</th>\n",
       "      <th>Pace</th>\n",
       "      <th>GS</th>\n",
       "      <th>GS/G</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>925000.0</td>\n",
       "      <td>97-01-30</td>\n",
       "      <td>Sainte-Marie</td>\n",
       "      <td>QC</td>\n",
       "      <td>CAN</td>\n",
       "      <td>CAN</td>\n",
       "      <td>74</td>\n",
       "      <td>190</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>40.03</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>175.7</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-0.38</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2250000.0</td>\n",
       "      <td>93-12-21</td>\n",
       "      <td>Ottawa</td>\n",
       "      <td>ON</td>\n",
       "      <td>CAN</td>\n",
       "      <td>CAN</td>\n",
       "      <td>74</td>\n",
       "      <td>207</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2850.59</td>\n",
       "      <td>290</td>\n",
       "      <td>13.3</td>\n",
       "      <td>112.5</td>\n",
       "      <td>14.1</td>\n",
       "      <td>0.18</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8000000.0</td>\n",
       "      <td>88-04-16</td>\n",
       "      <td>St. Paul</td>\n",
       "      <td>MN</td>\n",
       "      <td>USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>72</td>\n",
       "      <td>218</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2486.75</td>\n",
       "      <td>102</td>\n",
       "      <td>6.6</td>\n",
       "      <td>114.8</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.57</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3500000.0</td>\n",
       "      <td>92-01-07</td>\n",
       "      <td>Ottawa</td>\n",
       "      <td>ON</td>\n",
       "      <td>CAN</td>\n",
       "      <td>CAN</td>\n",
       "      <td>77</td>\n",
       "      <td>220</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1074.41</td>\n",
       "      <td>130</td>\n",
       "      <td>17.5</td>\n",
       "      <td>105.1</td>\n",
       "      <td>5.9</td>\n",
       "      <td>0.20</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1750000.0</td>\n",
       "      <td>94-03-29</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>ON</td>\n",
       "      <td>CAN</td>\n",
       "      <td>CAN</td>\n",
       "      <td>76</td>\n",
       "      <td>217</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.3</td>\n",
       "      <td>3459.09</td>\n",
       "      <td>425</td>\n",
       "      <td>8.3</td>\n",
       "      <td>99.5</td>\n",
       "      <td>21.8</td>\n",
       "      <td>0.27</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 155 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Salary      Born          City Pr/St Cntry  Nat  Ht   Wt   DftYr  DftRd  \\\n",
       "0   925000.0  97-01-30  Sainte-Marie    QC   CAN  CAN  74  190  2015.0    1.0   \n",
       "1  2250000.0  93-12-21        Ottawa    ON   CAN  CAN  74  207  2012.0    1.0   \n",
       "2  8000000.0  88-04-16      St. Paul    MN   USA  USA  72  218  2006.0    1.0   \n",
       "3  3500000.0  92-01-07        Ottawa    ON   CAN  CAN  77  220  2010.0    1.0   \n",
       "4  1750000.0  94-03-29       Toronto    ON   CAN  CAN  76  217  2012.0    1.0   \n",
       "\n",
       "   ...  OPS  DPS   PS     OTOI Grit   DAP   Pace    GS  GS/G  Age  \n",
       "0  ...  0.0 -0.2 -0.2    40.03    1   0.0  175.7  -0.4 -0.38   20  \n",
       "1  ... -0.2  3.4  3.2  2850.59  290  13.3  112.5  14.1  0.18   24  \n",
       "2  ...  3.7  1.3  5.0  2486.75  102   6.6  114.8  36.8  0.57   29  \n",
       "3  ...  0.0  0.4  0.5  1074.41  130  17.5  105.1   5.9  0.20   25  \n",
       "4  ... -0.1  1.4  1.3  3459.09  425   8.3   99.5  21.8  0.27   23  \n",
       "\n",
       "[5 rows x 155 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hockey.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('preprocessor',\n",
       "                 ColumnTransformer(n_jobs=None, remainder='drop',\n",
       "                                   sparse_threshold=0.3,\n",
       "                                   transformer_weights=None,\n",
       "                                   transformers=[('numerical',\n",
       "                                                  Pipeline(memory=None,\n",
       "                                                           steps=[('imputer',\n",
       "                                                                   SimpleImputer(add_indicator=False,\n",
       "                                                                                 copy=True,\n",
       "                                                                                 fill_value=None,\n",
       "                                                                                 missing_values=nan,\n",
       "                                                                                 strategy='mean',\n",
       "                                                                                 verbose=0)),\n",
       "                                                                  ('scaler',\n",
       "                                                                   StandardScaler(copy=True,\n",
       "                                                                                  with_...\n",
       "                                   verbose=False)),\n",
       "                ('regressor',\n",
       "                 RandomForestRegressor(bootstrap=True, criterion='mse',\n",
       "                                       max_depth=None, max_features='auto',\n",
       "                                       max_leaf_nodes=None,\n",
       "                                       min_impurity_decrease=0.0,\n",
       "                                       min_impurity_split=None,\n",
       "                                       min_samples_leaf=3, min_samples_split=2,\n",
       "                                       min_weight_fraction_leaf=0.0,\n",
       "                                       n_estimators=200, n_jobs=None,\n",
       "                                       oob_score=False, random_state=None,\n",
       "                                       verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import compose\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn import impute\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "y_train = hockey['Salary']\n",
    "X_train = hockey.drop('Salary', axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train)\n",
    "\n",
    "def make_pipeline(regressor=None):\n",
    "    \n",
    "    numeric_features = ['Ht', 'Wt', 'DftYr', 'DftRd', 'Ovrl', \n",
    "                        'GP', 'G', 'A', 'A1', 'A2', 'PTS', '+/-', 'E+/-', \n",
    "                        'PIM', 'Shifts', 'TOI', 'TOIX', 'TOI/GP', 'TOI/GP.1', \n",
    "                        'TOI%', 'IPP%', 'SH%', 'SV%', 'PDO', 'F/60', 'A/60', \n",
    "                        'Pct%', 'Diff', 'Diff/60', 'iCF', 'iCF.1', 'iFF', 'iSF', \n",
    "                        'iSF.1', 'iSF.2', 'ixG', 'iSCF', 'iRB', 'iRS', 'iDS', \n",
    "                        'sDist', 'sDist.1', 'Pass', 'iHF', 'iHF.1', 'iHA', 'iHDf', \n",
    "                        'iMiss', 'iGVA', 'iTKA', 'iBLK', 'iGVA.1', 'iTKA.1', \n",
    "                        'iBLK.1', 'BLK%', 'iFOW', 'iFOL', 'iFOW.1', 'iFOL.1', \n",
    "                        'FO%', '%FOT', 'dzFOW', 'dzFOL', 'nzFOW', 'nzFOL', \n",
    "                        'ozFOW', 'ozFOL', 'FOW.Up', 'FOL.Up', 'FOW.Down', \n",
    "                        'FOL.Down', 'FOW.Close', 'FOL.Close', 'OTG', '1G', 'GWG', \n",
    "                        'ENG', 'PSG', 'PSA', 'G.Bkhd', 'G.Dflct', 'G.Slap', 'G.Snap', \n",
    "                        'G.Tip', 'G.Wrap', 'G.Wrst', 'CBar ', 'Post', 'Over', 'Wide', \n",
    "                        'S.Bkhd', 'S.Dflct', 'S.Slap', 'S.Snap', 'S.Tip', 'S.Wrap', 'S.Wrst', \n",
    "                        'iPenT', 'iPenD', 'iPENT', 'iPEND', 'iPenDf', 'NPD', 'Min', \n",
    "                        'Maj', 'Match', 'Misc', 'Game', 'CF', 'CA', 'FF', 'FA', 'SF', \n",
    "                        'SA', 'xGF', 'xGA', 'SCF', 'SCA', 'GF', 'GA', 'RBF', 'RBA', \n",
    "                        'RSF', 'RSA', 'DSF', 'DSA', 'FOW', 'FOL', 'HF', 'HA', 'GVA', \n",
    "                        'TKA', 'PENT', 'PEND', 'OPS', 'DPS', 'PS', 'OTOI', 'Grit', 'DAP', \n",
    "                        'Pace', 'GS', 'GS/G', 'Age']\n",
    "    \n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', impute.SimpleImputer(strategy='mean')),\n",
    "        ('scaler', preprocessing.StandardScaler())])\n",
    "\n",
    "    categorical_features = ['Pr/St', 'Nat', 'Hand', 'Position', 'Team']\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', impute.SimpleImputer(strategy='constant', fill_value='unknown')),\n",
    "        ('onehot', preprocessing.OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "    preprocessor = compose.ColumnTransformer(transformers=[\n",
    "        ('numerical', numeric_transformer, numeric_features),\n",
    "        ('categorical', categorical_transformer, categorical_features)])\n",
    "\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                               ('regressor', regressor)])\n",
    "    \n",
    "    return pipeline\n",
    "\n",
    "regressor = RandomForestRegressor(n_estimators=200, min_samples_leaf=3)#, random_state=42)\n",
    "pipeline = make_pipeline(regressor)\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$213191.4934 medae on train dataset\n",
      "$557905.2204 medae on test dataset\n"
     ]
    }
   ],
   "source": [
    "y_pred = pipeline.predict(X_train)\n",
    "medae_value_train = metrics.median_absolute_error(y_train, y_pred)\n",
    "print(f\"${medae_value_train:.4f} medae on train dataset\")\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "medae_value_test = metrics.median_absolute_error(y_test, y_pred)\n",
    "print(f\"${medae_value_test:.4f} medae on test dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([671957.9168788 , 655746.98636436, 263071.76693706, 446086.61410985,\n",
       "       473756.65428842, 440055.18849206, 449005.8546746 , 528915.73645105,\n",
       "       371525.39586425, 630722.68831169])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median_absolute_error_scorer = make_scorer(metrics.median_absolute_error)\n",
    "cross_val_score(pipeline, \n",
    "                X_train, \n",
    "                y_train, \n",
    "                scoring=median_absolute_error_scorer,\n",
    "                cv=10)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
