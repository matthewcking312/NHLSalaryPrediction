{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Model\n",
    "\n",
    "### Group Name: The Big One\n",
    "\n",
    "### Group Members: Nicholas Parker, Matthew King, and Sean Sturtevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import compose\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn import impute\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read CSV's into pandas dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hockey = pd.read_csv(\"data/processed/hockey.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split into train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = hockey['Salary']\n",
    "X_train = hockey.drop('Salary', axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select nonpredictive_feature and separate numerical and categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nonpredictive_features = []\n",
    "# negImportanceDropList = ['Position', 'Team', 'PEND', 'TOIX', 'GA', 'xGA', 'iSCF', 'iPEND', 'sDist.1', 'iHF.1', 'PDO', 'Hand', 'SCA', 'iTKA.1', 'SA', 'IPP%', 'ixG', 'FA', 'Pace', 'iGVA.1', 'SV%', 'RBF', 'PENT', 'F/60', 'GVA', 'TKA', 'FOW', 'Diff/60']\n",
    "nonpredictive_features = ['ENG', 'Wide', 'Over', 'PSG', 'PSA', 'S.Dflct', 'G.Bkhd', 'Post', 'G.Dflct', 'CBar ', 'G.Slap', 'G.Snap', 'G.Wrst', 'G.Wrap', 'G.Tip', 'S.Bkhd', 'Min', 'S.Slap', 'Misc', 'Noise', 'DAP', 'Grit', 'PS', 'DPS', 'OPS', 'DSA', 'DSF', 'Game', 'Match', 'S.Snap', 'Maj', '1G', 'NPD', 'iPenDf', 'iPenD', 'iPenT', 'S.Wrst', 'S.Wrap', 'S.Tip', 'GWG', 'FOL.Down', 'OTG', 'PIM', 'iSF.1', 'iCF.1', 'Diff', 'Pct%', 'FOL.Close', 'TOI/GP.1', 'TOI/GP', 'TOI', 'Shifts', 'E+/-', 'sDist', '+/-', 'PTS', 'A2', 'A1', 'A', 'G', 'GP', 'Wt', 'Ht', 'iSF.2', 'Age', 'iFOW', 'iBLK', 'iFOL', 'dzFOL', 'nzFOW', 'nzFOL', 'ozFOW', 'ozFOL', 'dzFOW', 'FOL.Up', 'FOW.Up', 'iTKA', 'iGVA', 'iMiss', 'FOW.Down', 'iHF', 'FOW.Close', 'FO%', 'Position', 'Team', 'PEND', 'TOIX', 'GA', 'xGA', 'iSCF', 'iPEND', 'sDist.1', 'iHF.1', 'PDO', 'Hand', 'SCA', 'iTKA.1', 'SA', 'IPP%', 'ixG', 'FA', 'Pace', 'iGVA.1', 'SV%', 'RBF', 'PENT', 'F/60', 'GVA', 'TKA', 'FOW', 'Diff/60']\n",
    "# RedundantColDropList = ['TOI/GP', 'iCF', 'iSF', 'iSF.1', 'sDist', 'iHF', 'iGVA', 'iTKA', 'iBLK', 'iFOW', 'iFOL']\n",
    "\n",
    "numeric = [feature for feature in X_train.columns if np.issubdtype(X_train[feature], np.number) \n",
    "                      and feature not in nonpredictive_features]\n",
    "categorical = [feature for feature in X_train.columns if feature not in numeric\n",
    "                       and feature not in nonpredictive_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pipeline(knn=None):\n",
    "    \"\"\"\n",
    "    Creates pipeline that performs separate transformations on the categorical and numerical features.\n",
    "    \"\"\"\n",
    "    \n",
    "    numeric_features = numeric\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', impute.SimpleImputer(strategy='median')),\n",
    "        ('normalizer', preprocessing.Normalizer())])\n",
    "\n",
    "#     categorical_features = categorical\n",
    "#     categorical_transformer = Pipeline(steps=[\n",
    "#         ('imputer', impute.SimpleImputer(strategy='constant', fill_value='unknown')),\n",
    "#         ('onehot', preprocessing.OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "    preprocessor = compose.ColumnTransformer(transformers=[\n",
    "        ('numerical', numeric_transformer, numeric_features)])\n",
    "\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                               ('knn', knn)])\n",
    "    \n",
    "    return pipeline\n",
    "\n",
    "knn = KNeighborsRegressor()\n",
    "pipeline = make_pipeline(knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/MatthewKing/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:266: UserWarning: The total space of parameters 14 is smaller than n_iter=15. Running 14 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  70 out of  70 | elapsed:    0.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=Pipeline(memory=None,\n",
       "                                      steps=[('preprocessor',\n",
       "                                              ColumnTransformer(n_jobs=None,\n",
       "                                                                remainder='drop',\n",
       "                                                                sparse_threshold=0.3,\n",
       "                                                                transformer_weights=None,\n",
       "                                                                transformers=[('numerical',\n",
       "                                                                               Pipeline(memory=None,\n",
       "                                                                                        steps=[('imputer',\n",
       "                                                                                                SimpleImputer(add_indicator=False,\n",
       "                                                                                                              copy=True,\n",
       "                                                                                                              fill_value=None,\n",
       "                                                                                                              missing_values=nan,\n",
       "                                                                                                              st...\n",
       "                                              KNeighborsRegressor(algorithm='auto',\n",
       "                                                                  leaf_size=30,\n",
       "                                                                  metric='minkowski',\n",
       "                                                                  metric_params=None,\n",
       "                                                                  n_jobs=None,\n",
       "                                                                  n_neighbors=5,\n",
       "                                                                  p=2,\n",
       "                                                                  weights='uniform'))],\n",
       "                                      verbose=False),\n",
       "                   iid='warn', n_iter=15, n_jobs=None,\n",
       "                   param_distributions={'knn__n_neighbors': [5, 6, 7, 8, 9, 10,\n",
       "                                                             15],\n",
       "                                        'knn__weights': ['distance',\n",
       "                                                         'uniform']},\n",
       "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_random_cv():\n",
    "    \"\"\"\n",
    "    Define hyperparameter search space\n",
    "    Instantiate RandomizedSearchCV with the pipeline.\n",
    "    \"\"\"\n",
    "    \n",
    "#     algo = ['ball_tree', 'kd_tree', 'auto']\n",
    "    weights = ['distance', 'uniform']\n",
    "    neighbors = [5, 6, 7, 8, 9, 10, 15]\n",
    "    hyperparameters = dict(\n",
    "                          knn__n_neighbors=neighbors,\n",
    "                          knn__weights=weights)\n",
    "    \n",
    "    reg_random_cv = RandomizedSearchCV(pipeline, \n",
    "                                       hyperparameters, \n",
    "                                       cv=5, \n",
    "                                       n_iter=15, \n",
    "                                       verbose=1,\n",
    "                                       random_state=42)\n",
    "    \n",
    "    return reg_random_cv\n",
    "\n",
    "model = make_random_cv()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Report and and observe evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def place_commas(number): \n",
    "    return (\"{:,}\".format(number)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Median Absolute Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([511865.79670705, 406366.55776634, 774824.79832331, 627865.1442681 ,\n",
       "       677412.72878431, 682604.06552005, 372264.94354526, 750237.22557782,\n",
       "       437862.94302385, 624692.59372897])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median_absolute_error_scorer = make_scorer(metrics.median_absolute_error)\n",
    "cross_val_score(model.best_estimator_, \n",
    "                X_train, \n",
    "                y_train, \n",
    "                scoring=median_absolute_error_scorer,\n",
    "                cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$0.0 medae on train dataset\n",
      "$639,640.39 medae on test dataset\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.best_estimator_.predict(X_train)\n",
    "medae_value_train = place_commas(round(metrics.median_absolute_error(y_train, y_pred), 2))\n",
    "print(f\"${medae_value_train} medae on train dataset\")\n",
    "\n",
    "y_pred = model.best_estimator_.predict(X_test)\n",
    "medae_value_test = place_commas(round(metrics.median_absolute_error(y_test, y_pred), 2))\n",
    "print(f\"${medae_value_test:} medae on test dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Root Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$0.0 rmse on train dataset\n",
      "$1,610,360.39 rmse on test dataset\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.best_estimator_.predict(X_train)\n",
    "rmse_value_train = place_commas(round(np.sqrt(metrics.mean_squared_error(y_train, y_pred)), 2))\n",
    "print(f\"${rmse_value_train} rmse on train dataset\")\n",
    "\n",
    "y_pred = model.best_estimator_.predict(X_test)\n",
    "rmse_value_test = place_commas(round(np.sqrt(metrics.mean_squared_error(y_test, y_pred)), 2))\n",
    "print(f\"${rmse_value_test} rmse on test dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-11-d4c512683f52>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-11-d4c512683f52>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    medae_value_train = metrics.(y_train, y_pred)\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.best_estimator_.predict(X_train)\n",
    "medae_value_train = metrics.(y_train, y_pred)\n",
    "print(f\"${medae_value_train:.4f} medae on train dataset\")\n",
    "\n",
    "y_pred = model.best_estimator_.predict(X_test)\n",
    "medae_value_test = metrics.mean_squared_error(y_test, y_pred)\n",
    "print(f\"${medae_value_test:.4f} medae on test dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
