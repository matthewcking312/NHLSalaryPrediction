{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Model\n",
    "\n",
    "### Group Name: The Big One\n",
    "\n",
    "### Group Members: Nicholas Parker, Matthew King, and Sean Sturtevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import compose\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn import impute\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read CSV's into pandas dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hockey = pd.read_csv(\"data/processed/hockey.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split into train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = hockey['Salary']\n",
    "X_train = hockey.drop('Salary', axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select nonpredictive_feature and separate numerical and categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nonpredictive_features = []\n",
    "# negImportanceDropList = ['Position', 'Team', 'PEND', 'TOIX', 'GA', 'xGA', 'iSCF', 'iPEND', 'sDist.1', 'iHF.1', 'PDO', 'Hand', 'SCA', 'iTKA.1', 'SA', 'IPP%', 'ixG', 'FA', 'Pace', 'iGVA.1', 'SV%', 'RBF', 'PENT', 'F/60', 'GVA', 'TKA', 'FOW', 'Diff/60']\n",
    "nonpredictive_features = ['ENG', 'Wide', 'Over', 'PSG', 'PSA', 'S.Dflct', 'G.Bkhd', 'Post', 'G.Dflct', 'CBar ', 'G.Slap', 'G.Snap', 'G.Wrst', 'G.Wrap', 'G.Tip', 'S.Bkhd', 'Min', 'S.Slap', 'Misc', 'Noise', 'DAP', 'Grit', 'PS', 'DPS', 'OPS', 'DSA', 'DSF', 'Game', 'Match', 'S.Snap', 'Maj', '1G', 'NPD', 'iPenDf', 'iPenD', 'iPenT', 'S.Wrst', 'S.Wrap', 'S.Tip', 'GWG', 'FOL.Down', 'OTG', 'PIM', 'iSF.1', 'iCF.1', 'Diff', 'Pct%', 'FOL.Close', 'TOI/GP.1', 'TOI/GP', 'TOI', 'Shifts', 'E+/-', 'sDist', '+/-', 'PTS', 'A2', 'A1', 'A', 'G', 'GP', 'Wt', 'Ht', 'iSF.2', 'Age', 'iFOW', 'iBLK', 'iFOL', 'dzFOL', 'nzFOW', 'nzFOL', 'ozFOW', 'ozFOL', 'dzFOW', 'FOL.Up', 'FOW.Up', 'iTKA', 'iGVA', 'iMiss', 'FOW.Down', 'iHF', 'FOW.Close', 'FO%', 'Position', 'Team', 'PEND', 'TOIX', 'GA', 'xGA', 'iSCF', 'iPEND', 'sDist.1', 'iHF.1', 'PDO', 'Hand', 'SCA', 'iTKA.1', 'SA', 'IPP%', 'ixG', 'FA', 'Pace', 'iGVA.1', 'SV%', 'RBF', 'PENT', 'F/60', 'GVA', 'TKA', 'FOW', 'Diff/60']\n",
    "# RedundantColDropList = ['TOI/GP', 'iCF', 'iSF', 'iSF.1', 'sDist', 'iHF', 'iGVA', 'iTKA', 'iBLK', 'iFOW', 'iFOL']\n",
    "\n",
    "numeric = [feature for feature in X_train.columns if np.issubdtype(X_train[feature], np.number) \n",
    "                      and feature not in nonpredictive_features]\n",
    "categorical = [feature for feature in X_train.columns if feature not in numeric\n",
    "                       and feature not in nonpredictive_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pipeline(knn=None):\n",
    "    \"\"\"\n",
    "    Creates pipeline that performs separate transformations on the categorical and numerical features.\n",
    "    \"\"\"\n",
    "    \n",
    "    numeric_features = numeric\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', impute.SimpleImputer(strategy='median')),\n",
    "        ('normalizer', preprocessing.Normalizer())])\n",
    "\n",
    "    preprocessor = compose.ColumnTransformer(transformers=[\n",
    "        ('numerical', numeric_transformer, numeric_features)])\n",
    "\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                               ('knn', knn)])\n",
    "    \n",
    "    return pipeline\n",
    "\n",
    "knn = KNeighborsRegressor()\n",
    "pipeline = make_pipeline(knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed:    0.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=Pipeline(memory=None,\n",
       "                                      steps=[('preprocessor',\n",
       "                                              ColumnTransformer(n_jobs=None,\n",
       "                                                                remainder='drop',\n",
       "                                                                sparse_threshold=0.3,\n",
       "                                                                transformer_weights=None,\n",
       "                                                                transformers=[('numerical',\n",
       "                                                                               Pipeline(memory=None,\n",
       "                                                                                        steps=[('imputer',\n",
       "                                                                                                SimpleImputer(add_indicator=False,\n",
       "                                                                                                              copy=True,\n",
       "                                                                                                              fill_value=None,\n",
       "                                                                                                              missing_values=nan,\n",
       "                                                                                                              st...\n",
       "                                                                  metric_params=None,\n",
       "                                                                  n_jobs=None,\n",
       "                                                                  n_neighbors=5,\n",
       "                                                                  p=2,\n",
       "                                                                  weights='uniform'))],\n",
       "                                      verbose=False),\n",
       "                   iid='warn', n_iter=15, n_jobs=None,\n",
       "                   param_distributions={'knn__algorithm': ['ball_tree',\n",
       "                                                           'kd_tree', 'auto'],\n",
       "                                        'knn__n_neighbors': [8, 9, 10, 15],\n",
       "                                        'knn__weights': ['distance',\n",
       "                                                         'uniform']},\n",
       "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_random_cv():\n",
    "    \"\"\"\n",
    "    Define hyperparameter search space\n",
    "    Instantiate RandomizedSearchCV with the pipeline.\n",
    "    \"\"\"\n",
    "    \n",
    "    algo = ['ball_tree', 'kd_tree', 'auto']\n",
    "    weights = ['distance', 'uniform']\n",
    "    neighbors = [8, 9, 10, 15]\n",
    "    hyperparameters = dict(knn__algorithm=algo,\n",
    "                          knn__n_neighbors=neighbors,\n",
    "                          knn__weights=weights)\n",
    "    \n",
    "    reg_random_cv = RandomizedSearchCV(pipeline, \n",
    "                                       hyperparameters, \n",
    "                                       cv=5, \n",
    "                                       n_iter=15, \n",
    "                                       verbose=1,\n",
    "                                       random_state=42)\n",
    "    \n",
    "    return reg_random_cv\n",
    "\n",
    "model = make_random_cv()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Report and and observe evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def place_commas(number): \n",
    "    return (\"{:,}\".format(number)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape_metric(y_test, y_pred):\n",
    "    y_test, y_pred = np.array(y_test), np.array(y_pred)\n",
    "    n = len(y_test)\n",
    "    running_sum = 0\n",
    "    for i in range(n):\n",
    "        running_sum += abs((y_test[i] - y_pred[i])/y_test[i])\n",
    "    return running_sum/n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Median Absolute Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 706111.11111111,  585277.77777778,  447083.33333333,\n",
       "        979722.22222222,  515277.77777778,  694444.44444444,\n",
       "        415744.44444444,  511388.88888889, 1165277.77777778,\n",
       "        613055.55555556])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median_absolute_error_scorer = make_scorer(metrics.median_absolute_error)\n",
    "cross_val_score(model.best_estimator_, \n",
    "                X_train, \n",
    "                y_train, \n",
    "                scoring=median_absolute_error_scorer,\n",
    "                cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$529,722.22 medae on train dataset\n",
      "$588,888.89 medae on test dataset\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.best_estimator_.predict(X_train)\n",
    "medae_value_train = place_commas(round(metrics.median_absolute_error(y_train, y_pred), 2))\n",
    "print(f\"${medae_value_train} medae on train dataset\")\n",
    "\n",
    "y_pred = model.best_estimator_.predict(X_test)\n",
    "medae_value_test = place_commas(round(metrics.median_absolute_error(y_test, y_pred), 2))\n",
    "print(f\"${medae_value_test:} medae on test dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Root Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$1,513,596.24 rmse on train dataset\n",
      "$1,511,360.12 rmse on test dataset\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.best_estimator_.predict(X_train)\n",
    "rmse_value_train = place_commas(round(np.sqrt(metrics.mean_squared_error(y_train, y_pred)), 2))\n",
    "print(f\"${rmse_value_train} rmse on train dataset\")\n",
    "\n",
    "y_pred = model.best_estimator_.predict(X_test)\n",
    "rmse_value_test = place_commas(round(np.sqrt(metrics.mean_squared_error(y_test, y_pred)), 2))\n",
    "print(f\"${rmse_value_test} rmse on test dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean Absolute Percentage Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60.17% mape on train dataset\n",
      "59.68% mape on test dataset\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.best_estimator_.predict(X_train)\n",
    "mape_value_train = round(mape_metric(y_train, y_pred)*100, 2)\n",
    "print(f\"{mape_value_train}% mape on train dataset\")\n",
    "\n",
    "y_pred = model.best_estimator_.predict(X_test)\n",
    "mape_value_test = round(mape_metric(y_test, y_pred)*100, 2)\n",
    "print(f\"{mape_value_test}% mape on test dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
